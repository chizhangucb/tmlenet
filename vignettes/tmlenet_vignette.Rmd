---
title: "Using tmlenet R Package for Estimation of Causal Effects in Observational Network Data"
author: "Oleg Sofrygin and Mark J. van der Laan"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    highlight: haddock
    keep_tex: true
    latex_engine: xelatex
bibliography: 
  - SimCausal_2014.bib
  - R-Pckgs.bib
  - TMLE_networks_2014.bib
vignette: >
  %\VignetteIndexEntry{tmlenet Package: Estimating Causal Effects in Observational Network Data}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
<!-- output: rmarkdown::html_vignette -->
<!-- output:
  html_document:
    toc: true
    fig_caption: true
    fig_retina: NULL
    theme: united
    highlight: haddock -->
<!-- output:
  pdf_document:
    toc: true
    highlight: haddock
    keep_tex: true
    latex_engine: xelatex -->
<!-- highlight: zenburn -->
<!-- “default”, “tango”, “pygments”, “kate”, “monochrome”, “espresso”, “zenburn”, and “haddock”  -->


```{r, include=FALSE, results='hide'}
  require(methods)
  require(knitr)
  exportTexOnly=FALSE # do not include any chunks in the final result (R code is still evaluated)
  cache_opt <- TRUE
  opts_chunk$set(fig.path='figure/beamer-',fig.align='center',fig.show='hold',size='footnotesize')
  # to crop white space in output figures:
  knit_hooks$set(pdfcrop = hook_pdfcrop)
  # To disable syntax color highlighing of R code in the entire document
  # opts_chunk$set(highlight=FALSE)
  # To change the background color on knitR output from default gray to white:
  # opts_chunk$set(background='white')
  opts_chunk$set(include=!exportTexOnly)
  # options(width=80)  # make the printing fit on the page
  options(width=90)  # make the printing fit on the page
  set.seed(1121)   # make the results repeatable
```

```{r, include=FALSE, eval=FALSE, results='hide'}
  # Need to first load that packages that need to be cited:
  # require(tmlenet)
  # require(simcausal)
  # require(data.table)
  # require(ggplot2)
  # require(ltmle)
  # require(igraph)
  # require(lavaan); require(lavaan.survey); require(sem); require(semPLS); require(OpenMx); require(simsem)
  # require(gems); require(aftgee); require(survsim)
  # # # Select packages to cite:
  # citPkgs <- names(sessionInfo()$otherPkgs)
  # citPkgs <- c(citPkgs, "base")
  # require(knitr)
  # # Write the bibtex file:
  # write_bib(citPkgs, file = "R-Pckgs_tmp.bib")
```

# Introduction

This vignette describes how to combine the structural equation and network models to simulate the network-dependent observational data using the `simcausal` `R` package [@R-simcausal] and then use `tmlenet` `R` package [@R-tmlenet] to estimate the effects of single time point stochastic interventions using such data. To learn more about the general functionality of the `simcausal` package, see the corresponding vignette titled: "simcausal Package: Simulations with Complex Longitudinal Data". To learn more about using the `simcausal` package specifically for conducting the network-based simulations, see the vignette "simcausal Package: Simulations with Networks-Based Dependent-Data Structural Equation Models". 

The `tmlenet` R package performs estimation of average causal effects for single time point interventions in network-dependent (non-iid) data in the presence of interference and/or spillover. Currently implemented estimation algorithms are the targeted maximum likelihood estimation (TMLE), Horvitz-Thompson or the inverse-probability-of-treatment (IPTW) estimator and the parametric G-computation estimator. The user-specified interventions can be either static, dynamic or stochastic. Asymptotically correct influence-curve-based confidence intervals are also constructed for the TMLE and IPTW. For more information behind the methods implemented the `tmlenet` package, see @vdL2014nets.


## Installation

To install the `simcausal` and `tmlenet` packages, run the code below: 

```{r, eval=FALSE}
install.packages("simcausal", dependencies = TRUE)
install.packages("tmlenet", dependencies = TRUE)
```

To install the development version of these packages (note, requires the `devtools` package):

```{r, eval=FALSE}
devtools::install_github('osofr/simcausal', build_vignettes = FALSE)
devtools::install_github('osofr/tmlenet', build_vignettes = FALSE)
```


## The input data and the network summary measures

The input data are assumed to consist of rows of unit-specific observations, with each row `i` represented by variables (`F.i`,`W.i`,`A.i`,`Y.i`), where `F.i` is a vector of "__friend IDs__" of unit `i` (also referred to as `i`'s "__network__"), `W.i` is a vector of `i`'s baseline covariates, `A.i` is `i`'s exposure (either binary, categorical or continuous) and `Y.i` is `i`'s binary outcome. 

Each exposure `A.i` depends on (possibly multivariate) baseline summary measure(s) `sW.i`, where `sW.i` can be any user-specified function of `i`'s baseline covariates `W.i` and the baseline covariates of `i`'s friends in `F.i` (all `W.j` such that `j` is in `F.i`). Similarly, each outcome `Y.i` depends on `sW.i` and (possibly multivariate) summary measure(s) `sA.i`, where `sA.i` can be any user-specified function of `i`'s baseline covariates and exposure (`W.i`,`A.i`) and the baseline covariates and exposures of `i`'s friends (all `W.j`,`A.j` such that `j` is in `i`'s friend set `F.i`). 

The summary measures (`sW.i`,`sA.i`) are defined simultaneously for all `i` with functions `def.sW` and `def.sA`. It is assumed that (`sW.i`,`sA.i`) have the same dimensionality across `i`. The function `eval.summaries` can be used for evaluating these summary measures.

All estimation is performed by calling the `tmlenet` function. The vector of friends `F.i` can be specified either as a single column in the input data (where each `F.i` is a string of friend IDs or friend row numbers delimited by character `sep`) or as a separate input matrix of network IDs (where each row is a vector of friend IDs or friend row numbers). Specifying the network as a matrix generally results in significant improvements to run time. See `tmlenet` function help file for additional details on how to specify these and the rest of the input arguments.



## Using syntax `'[['` for referencing the network variable values

The `network` function call that defines the network of friends can be added to a growing `DAG` object with syntax `'+network(...)'`, much like a new `node` is added to a growing `DAG` object when sampling iid observations. Subsequently defined nodes (`node` function calls) can employ the double square bracket subsetting syntax `'[['` to reference previously simulated node values for specific friends in $F_i$, simultaneously across all observations `i`. 


For example, using the expression `'VarName[[net_indx]]'` inside the formula of the node function call, will look-up the values of the node `'VarName'` for observations in $F_i[net\_indx]$,  simultaneously across all $i \in 1,\ldots,n$. When `net_indx` is a vector, the evaluation result of the expression `'VarName[[net_indx]]'` is a matrix with `length(net_indx)` columns and `n` rows, and when `net_indx` is a scalar, this evaluation results in a vector. We note that indexing variable `net_indx` above can be a non-negative integer-valued vector, with values starting from 0 and bounded above by the specially reserved integer constant `Kmax`. Using `0` as part of the `net_indx` vector refers to the actual `'VarName'` node values of the observations, hence the expression `'VarName[[0]]'` is equivalent to just using `'VarName'`. When `net_indx` is 1, the expression refers to the node `'VarName'` values for observations in $F_i[1]$, across all $i \in 1,\ldots,n$ (that is, the value of `'VarName'` of `i`'s first friend $F_i[1]$, if the friend exists and `NA` otherwise), and so on, up to `net_indx` value of `Kmax`, which would reference the last friend node values of `VarName`, as defined by observation $F_i[Kmax]$, if `i` has a total of `Kmax` friends and is `NA` otherwise. Also note that the reserved variable name `'Kmax'` can be explicitly used as part of the friend node indexing, i.e., using the node formula expression `'VarName[[Kmax]]'`, will first set the variable `Kmax` to the maximal number of friends observed in a specific network, and then evaluate this node expression according to the rule just described. By default, the expression `'VarName[[k]]'` evaluates to missing (i.e., `'NA'`) for observations that have fewer than `k` friends. This default behavior however can be changed to return `0` instead of `NA`, by passing an additional argument `'replaceNAw0=TRUE'` to the corresponding `node` function call.


Finally, we note that `simcausal` does not allow simultaneous friend references of the same node, that is, each newly added node can be defined only as a function of the nodes that have already been added to the structural equation model. For example, for unit `i`, a node named `Var` cannot depend on the same node `Var` values of `i`'s friends.


## Network-based covariate summary measures

One can define the summary measures of the network covariates by specifying a node formula that applies an `R` function to the evaluation result of the expression `VarName[[net_indx]]`, where `net_indx` is a vector, and the evaluation result of `VarName[[net_indx]]` is a matrix. The rules for defining and applying such summary measures are identical to the rules for defining and applying the summary measures to the evaluation result of the time-varying node, such as the result of the expression `VarName[t_indx]`, where `t_indx` is a vector. For example, one can use `sum(VarName[[net_indx]])` to define a summary measure as a sum of `VarName` values of friends in $F_i[net\_indx]$, across all observations $i \in 1,\ldots,n$. Similarly, use `mean(VarName[[net_indx]])` to define a summary measure as a mean of `VarName` values of friends in $F_i[net\_indx]$, across all `i`. For more details on defining such summary functions see the vignette "simcausal: Causal Simulation Package" and the examples below.


# Brief introduction to estimation with `tmlenet` with running examples

We will use the sample dataset (`W`=(`W1`,`W2`,`W3`),`A`,`Y`) and the sample network matrix of friend IDs (`F`) that come along with the package:

```{r}
library(tmlenet)
# require(simcausal)

data(df_netKmax6)
head(df_netKmax6)

data(NetInd_mat_Kmax6)
head(NetInd_mat_Kmax6)
```

The estimation algorithm assumes that the outcomes in `Y.i` for units `i=1,...,N` are conditionally independent,
given the summary measures defined in `def_sW` and the summary measures defined in `def_sA`.

When no additional assumptions about the conditional independence of outcomes `Y.i` can be made 
(beyond the dependence on the network structure),
one can define the summary measures `sW` and `sA` non-parametrically, e.g., 
for each observation `i`: include in `sW` all baseline covariates of unit `i` and 
all baseline covariates of `i`'s friends; include in `sA` the exposure of unit `i` and
all exposures of `i`'s friends. 

The example below does just that, defining  `sW`:=(`netW1`,`netW2`,`netW3`) and `sA`:=`netA`, 
where `netVar` is a summary measure of dimension `Kmax+1` and includes `Var` values of each 
unit as well as `Var` values of all friends of each unit:

```{r}
Kmax <- ncol(NetInd_mat_Kmax6)
def_sW <- def.sW(netW1 = W1[[0:Kmax]], netW2 = W2[[0:Kmax]], netW3 = W3[[0:Kmax]])
def_sA <- def.sA(netA = A[[0:Kmax]])
```

Note that the summary measure `nF` (number of friends for each unit) is always added automatically to 
`def.sW` function calls (only once), but not to `def.sA`.

A helper function that can pre-evaluate the above summary measures based on the input data:

```{r}
eval_res <- eval.summaries(sW = def_sW, sA = def_sA,  Kmax = 6, data = df_netKmax6,
                          NETIDmat = NetInd_mat_Kmax6)
```

Contents of the list returned by `eval.summaries()`:

```{r}
# Matrix of sW summary measures:
head(eval_res$sW.matrix) 
# Matrix of sA summary measures:
head(eval_res$sA.matrix)
# matrix of network IDs: 
head(eval_res$NETIDmat)
```

Observed data summary measures (sW,sA) and network stored in one object:

```{r}
# eval_res$DatNet.ObsP0
class(eval_res$DatNet.ObsP0)
```

In the example below, we estimate mean population outcome under deterministic intervention that assigns all `A` to 0
(network specified via a matrix of friend IDs). Note that can also use previously evaluated
summary measures object `DatNet.ObsP0` as input to `tmlenet`, avoiding the need to specify the arguments
(`data`,`NETIDmat`,`Kmax`,`sW`,`sA`) for the second time.

```{r}
res1 <- tmlenet(data = df_netKmax6, NETIDmat = NetInd_mat_Kmax6, Kmax = Kmax, 
                sW = def_sW, sA = def_sA,
                Anode = "A", Ynode = "Y",
                f_gstar1 = 0L, optPars = list(n_MCsims = 1))
res1$EY_gstar1$estimates
res1$EY_gstar1$vars
res1$EY_gstar1$CIs
```

By default, the conditional expectation `E[Y=1|...]` (`Qform` argument) is estimated by including all
summary measures in `sW` and `sA` as predictors in the logistic regression for the outcome `Y`.
Similarly, by default, the observed exposure model `P(sA|sW)` (`hform.g0` argument) is estimated
as the conditional probability of observing the summary measures defined in `sA`, given the summary measures
defined in `sW`. Finally, the intervention exposure model `P(sA^*|sW)` (`hform.gstar` 
argument) is estimated by first replacing all observed exposures in `A` with those generated from
the intervention function specified in `f_gstar1` (new exposures denoted by `A^*`) and then building
the same summary measures defined in `sW` and `sA` using exposures `A^*` instead of `A`
(new summary measures denoted by `sA^*`). By default, the intervention exposure model `P(sA^*|sW)`
will be estimated as the conditional probability of observing the intervention-based summary measures in `sA^*` 
(`sA^*` built with `A^*` using the same summary mappings as in `sA`), given the summary measures defined in `sW`.

One can change this default behavior and use the arguments `Qform`, `hform.g0` and `hform.gstar`
to select a subset of the summary measures in `sW`,`sA` to be included in each of the three models described above.
For example, below we are assuming that the outcomes in `Y` only depend on the summary measures `netA`,`netW2` 
(regression `"Y~netA+netW2"`) and hence the observed exposure model is given by `P(netA|netW2)` (regression `"netA~netW2"`) and we also know that `f_gstar1` defines a static intervention `A^*=1` and hence `sA^*` is degenerate and doesn't depend on any baseline covariates and will be estimated here with a simplified regression model (regression `"netA ~ nF"`):

```{r}
res2 <- tmlenet(DatNet.ObsP0 = eval_res$DatNet.ObsP0,
                    Anode = "A", Ynode = "Y", 
                    Qform = "Y ~ netA + netW2",
                    hform.g0 = "netA ~ netW2",
                    hform.gstar = "netA ~ nF",
                    f_gstar1 = 0L, optPars = list(n_MCsims = 1))
res2$EY_gstar1$estimates
res2$EY_gstar1$vars
res2$EY_gstar1$CIs
```

One might be also willing to make dimension reducing assumptions about the dependence of each `Y.i` on its 
network. For example, here we assume that each `Y.i` depends on its network's baseline covariates only
through a sum of its friends' values of `W3` and `Y.i` depends on its network's exposures only through a sum 
of `i`'s friends' interactions `(1-A)*(W2)` (while we assume `Y.i` still depends on `i`'s baseline covariates and
`i`'s exposure):

```{r}
def_sW <- def.sW(W = c(W1,W2,W3)) +
          def.sW(sum.netW3 = sum(W3[[1:Kmax]]), replaceNAw0=TRUE)

def_sA <- def.sA(A) +
          def.sA(sum.netAW2 = sum((1-A[[1:Kmax]])*W2[[1:Kmax]]), replaceNAw0=TRUE)

eval_res <- eval.summaries(sW = def_sW, sA = def_sA, Kmax = 6, data = df_netKmax6,
                            NETIDmat = NetInd_mat_Kmax6, verbose = TRUE)

res3 <- tmlenet(DatNet.ObsP0 = eval_res$DatNet.ObsP0,
                Anode = "A", Ynode = "Y",
                Qform = "Y ~ A + sum.netAW2 + W + sum.netW3 + nF",
                hform.g0 = "A + sum.netAW2 ~ sum.netW3",
                hform.gstar = "A + sum.netAW2 ~ sum.netW3",
                f_gstar1 = 0, optPars = list(n_MCsims = 1))
res3$EY_gstar1$estimates
```

Note that the above model specified by `Qform` includes all summary measures in `sW`,`sA`, and hence is equivalent to the default regression model that would have been used if `Qform` was omitted.

One can specify any intervention of interest, for example below we estimate the counterfactual mean outcome under intervention that randomly assigns 20% of the population to exposure `A=1`. Note that we are also increasing the number of Monte-Carlo simulations
from 1 to 100.

```{r}
f.A_.2 <- function(data, ...) rbinom(n = nrow(data), size = 1, prob = 0.2)
res4 <- tmlenet(data = df_netKmax6, NETIDmat = NetInd_mat_Kmax6, Kmax = Kmax,
                sW = def_sW, sA = def_sA, 
                Anode = "A", Ynode = "Y", 
                f_gstar1 = f.A_.2, optPars = list(n_MCsims = 100))
res4$EY_gstar1$estimates
```

To estimate the average treatment effect (ATE) for two interventions (static or stochastic), specify the second intervention function using the argument `optPars(f_gstar2 = ...)`. In the example below, the intervention `f_gstar1`
statically sets everyone's exposure to `A=1` and the intervention `f_gstar2` statically sets everyone's exposure to `A=0`:

```{r}
res5 <- tmlenet(data = df_netKmax6, NETIDmat = NetInd_mat_Kmax6, Kmax = Kmax,
                sW = def_sW, sA = def_sA, Anode = "A", Ynode = "Y",
                f_gstar1 = 1, optPars = list(f_gstar2 = 0, n_MCsims = 1))
res5$ATE$estimates
```


# Example of a simulation study with a single time point stochastic intervention

In this example we simulate a network of connections on $n$ units, along with the unit-specific data with 3 binary baseline covariates, $W_i = (W_i(1),W_i(2),W_i(3))$, for $i=1,\ldots,n$. In addition, we also simulate the observed unit-specific exposures $sA_i$, which are continuous and are normally distributed when conditioned on $W_i$, with a common (in $i$) conditional density given by $g_0(sA_i|W_i)$ and parameterized as normal with $\sigma^2=1$ and $$\mu(W_i)= 0.98*W_i(1)+0.58*W_i(2)+0.33*W_i(3).$$ We define the stochastic intervention by known (and common in $i$) density $g^*$, that depends on $g_0$. This new (intervened) exposure under stochastic intervention $g^*$ is denoted by random variable $sA^*_i$ and it is set equal to $sA_i+shift$, for known constant $shift>0$, if the following condition holds: $$\exp\{shift * (sA_i - \mu(W_i) + shift/2)\} \geq trunc \tag{*},$$ for known truncation constant $trunc>0$, and otherwise, the intervention is to keep the exposure unchanged, setting: $$sA^*_i = sA_i.$$ Finally, the outcome $Y_i$, for each unit $i$, is assumed to depend on $i$'s baseline covariates in $W_i$ and $i$'s exposure $sA_i$, as well as the baseline covariate values and exposures of $i$'s friends via the following summary measures: $$W^s_i:=1/|F_i|\sum_{j \in F_i}{W_j}\ \mbox{and}\ A^s_i:=1/|F_i|\sum_{j \in F_i}{sA_j}.$$


Our target causal quantity is defined with respect to $n$ $i$-specific counterfactual outcomes $Y^{*}_i$, under stochastic intervention $g^*$. The counterfactual outcomes are generated by first replacing the structural equations for the observed exposures $sA_i$ (defined by $g_0(sA_i|W_i)$), with the new structural equations for generating $sA^*_i$ (defined by the intervention $g^*(sA^*_i|A_i,W_i)$) and then sampling the outcomes $Y^*_i$ from this modified data-generating distribution, where we use the new notation $Y^{*}_i$, instead of the old outcome $Y_i$, to denote the fact that the distribution of the outcome $Y_i$ has been modified by replacing $g_0$ with intervention $g^*$. Our causal quantity is denoted by $\psi_0$ and we define it as the sample-average of unit-specific expected outcomes, i.e., $$\psi_0 := 1/n\sum_{i=1}^n{E[Y^*_i]},$$ which we will evaluate by using the `simcausal` package.

## Specifying the structural equation model for dependent data

In order to perform network-based simulations with the `simcausal` package one has to first define the sampling distribution function for the network, and this function will be referred to as the *network generator* function. In general the network generator can be any user-supplied function that returns a network $\mathbf{F}$ for `n` observations. The next step is then to *register* the network generator with a call to the `network` function, specifying the network generator function name as an argument `netfun`. This network can then serve as a backbone for defining the dependent-data structural equation models, in which any variable can be a function of the previously defined variable values of the unit's friends. For additional examples of such network generators, as well as the detailed specifications of how to define such functions, we refer to the `simcausal` package vignette "Simulations with Networks-Based Dependent-Data Structural Equation Models" [@R-simcausal]. We define the network generator `generate.igraph.k.regular` below that samples a regular directed graph (all nodes have the same degree `Kmax`) using the `sample_k_regular` function of the `igraph` package [@igraph]. 

```{r, results='hide', message=FALSE}
library(igraph)
generate.igraph.k.regular <- function(n, Kmax, ...) {
    if (n < 20) Kmax <- 5
    igraph.reg <- igraph::sample_k_regular(no.of.nodes = n, 
                                        k = Kmax, 
                                        directed = TRUE, 
                                        multiple = FALSE)
    sparse_AdjMat <- simcausal::igraph.to.sparseAdjMat(igraph.reg)
    NetInd_out <- simcausal::sparseAdjMat.to.NetInd(sparse_AdjMat)
    return(NetInd_out$NetInd_k)
  }
```

Below, we use the `simcausal` `R` package [@R-simcausal] to define the structural equation model that uses the above network generating function `generate.igraph.k.regular`, by first  adding the above network generator, then defining the structural equation model for baseline covariates (`W1`, `W2` and `W3`), then defining the structural equation model for the observed exposure `sA` and, finally, defining the binary outcome `Y` that depends on the network structure of friends exposures.

```{r, results='hide', message=FALSE}
library(simcausal)
options(simcausal.verbose=FALSE)
Kmax <- 10
D <- DAG.empty()
D <- D + network("NetInd_k", Kmax = Kmax, netfun = "generate.igraph.k.regular")

D <- D +
    node("W1", distr = "rbern", prob = 0.5) +
    node("W2", distr = "rbern", prob = 0.3) +
    node("W3", distr = "rbern", prob = 0.3) +
    node("sA.mu", distr = "rconst", const = (0.98 * W1 + 0.58 * W2 + 0.33 * W3)) +
    node("sA", distr = "rnorm", mean = sA.mu, sd = 1) +
    node("new.sA", distr = "rconst", const = sA) +
    node("probY", distr = "rconst",
      const = plogis( 
                      -0.35*new.sA +
                      -0.5*ifelse(nF > 0, sum(new.sA[[1:Kmax]])/nF, 0) +
                      -0.5*ifelse(nF > 0, sum(W1[[1:Kmax]])/nF, 0) +
                      -0.5*W1 - 0.58*W2 - 0.33*W3),
      replaceNAw0 = TRUE) +
    node("Y", distr = "rbern", prob = probY)

Dset <- set.DAG(D)
```

## Evaluating the true value of the causal quantity

We now evaluate $\psi_0$ under intervention $g^*$ via Monte-Carlo simulation by sampling the counterfactual outcome $Y^*$ from the modified data-generating distribution that replaces $g_0$ with $g^*$. In order to do that, we first define an action named `gstar`, that overrides the distribution of the observed node `new.sA`, with a new distribution given by the common in $i$ density $g^*$, which is as described above, i.e., we shift the value of the observed continuous exposure `sA` only if the condition $(*)$ is satisfied for $trunc$ and $shift$ constants provided below:

```{r}
trunc <- 4
shift <- 1

Dset <- Dset + 
  action("gstar", 
    nodes = node("new.sA",
      distr = "rconst", 
      const = ifelse(exp(shift * (sA + shift - sA.mu - shift/2)) > trunc,
                    sA, sA + shift)),
    trunc = trunc, shift = shift)
```

Next, we sample a network of $n=50,000$, sample $Y_i^*$, for $i=1,\ldots,n$, based on the action `gstar` defined above and finally, evaluate the Monte-Carlo estimate of $\psi_0$:

```{r}
`%+%` <- function(a, b) paste0(a, b)
nfull <- 50000
datFull <- sim(Dset, actions="gstar", n = nfull, rndseed = 54321)[[1]]
psi0 <- mean(datFull$Y)
print(c("psi0: ", psi0))
```

## Simulating observed data, obtaining the network

Next, we simulate the observed data from the above defined dependent data generating distribution and save the network ID matrix, as shown below:

```{r}
nsamp <- 50
datO <- sim(Dset, n = nsamp, rndseed = 54321)
print("mean(datO$Y): " %+% mean(datO$Y));

NetInd_mat <- attributes(datO)$netind_cl$NetInd
nF <- attributes(datO)$netind_cl$nF
datO <- datO[,c("W1", "W2", "W3", "sA", "Y")]
print(head(datO))
print(head(NetInd_mat))
```

## Plotting

We can visualize the observed network using `plot.igraph` function in `igraph` package [@igraph], as shown below.

```{r netplot3, fig.width=7, fig.height=5, message=FALSE, fig.cap = "Directed random regular graph (all nodes have the same degree) from Example 3"}
g <- sparseAdjMat.to.igraph(NetInd.to.sparseAdjMat(NetInd_mat, nF = nF))
par(mar=c(.1,.1,.1,.1))
plot.igraph(g,
    layout=layout.circle,
    vertex.size=5,
    vertex.label.cex=.5,
    edge.arrow.size=.1)
```

Similarly, we can plot the functional relationships between the nodes in the `DAG` object `Dset`, as shown below.

```{r DAGplot3, fig.width=6, fig.height=5, message=FALSE, fig.cap = "Functional relationships between the nodes of the structural equation model from Example 3"}
par(mar=c(.1,.1,.1,.1))
plotDAG(Dset, vertex_attrs = list(size = 18, label.cex = 0.8))
```

## Estimation of causal effects in observational network data using `tmlenet` `R` package

Function `tmlenet` in package `tmlenet` can perform the estimation of the mean outcome under stochastic intervention `f.gstar`, using the above sampled observed data `datO`, the network defined by the matrix `NetInd_mat` and the argument `Qform` to specify the regression model for the conditional mean of the outcome `Y`, given summary measures $W^s,A^s$.


## Stochastic intervention

Below we give an example of the user-specified stochastic intervention that will be provided as an input to the `tmlenet` function. The user-defined stochast intervention is a function that should always return a vector of new treatment assignments. The example below uses the shifted normal intervention, which is the same intervention defined above using the `DAG` object of the `simcausal` package. This function returns a stochastic intervention function intervening on `sA`, for given `shift` and `trunc` constants.

```{r, message=FALSE}
library(tmlenet)
options(tmlenet.verbose = FALSE)

nsamp <- 5000
datO <- sim(Dset, n = nsamp, rndseed = 54321)
NetInd_mat <- attributes(datO)$netind_cl$NetInd
nF <- attributes(datO)$netind_cl$nF
datO <- datO[,c("W1", "W2", "W3", "sA", "Y")]
print("mean(datO$Y): " %+% mean(datO$Y));
```

```{r}
create_f.gstar <- function(shift, trunc) {
  f.gstar <- function(data, ...) {
    sA.mu <- 0.98 * data[,"W1"] + 0.58 * data[,"W2"] + 0.33 * data[,"W3"]
    sA <- data[,"sA"]
    untrunc.sA.gstar <- sA + shift
    # ratio of P_g^*(sA=sa|W)/P_g0(sA=sa|W) for sa=sA generated under g^*:
    r.new.sA <- exp(shift * (untrunc.sA.gstar - sA.mu - shift / 2))
    trunc.sA.gstar <- ifelse(r.new.sA > trunc, sA, untrunc.sA.gstar)
    return(trunc.sA.gstar)
  }
  return(f.gstar)
}
```

## Summary measures

Define the (network) summary measures $W^s$ and $A^s$ for the `tmlenet` function input using a syntax similar to the `simcausal` syntax above. The function `def.sW` is used to specify the baseline-only summary measures $W^s:=w_i(\mathbf{W})$ and the function `def.sA` is used to specify the exposure and baseline summary measures $A^s:=a_i(\mathbf{A},\mathbf{W})$. This summary measures form the basis of the `exposure model`, i.e., $P(A^s|W^s)$, where the latter probability model is defined under the true exposure mechanism $\mathbf{g}_0(\mathbf{A}|\mathbf{W})$ and the user-specified stochastic intervention $\mathbf{g}^*(\mathbf{A}^*|\mathbf{W})$, where the stochastic intervention of interest is defined with the argument `f_gstar1` of the `tmlenet` function.


```{r, results='hide', message=FALSE}
def_sA <- def.sA(sA,
                net.mean.sA = ifelse(nF > 0, rowSums(sA[[1:Kmax]])/nF, 0),
                replaceNAw0 = TRUE)

def_sW <- def.sW(W1, W2, W3) +
          def.sW(net.mean.W1 = ifelse(nF > 0, rowSums(W1[[1:Kmax]])/nF, 0),
                replaceNAw0 = TRUE)
```


## Pre-evaluation of the summary measures

```{r}
Kmax <- 10
trunc.const <- 4
shift.const <- 1

res <- eval.summaries(sW = def_sW, sA = def_sA, 
                      Kmax = Kmax, data = datO,
                      NETIDmat = NetInd_mat, verbose = TRUE)
names(res)
```

## Estimation example 1.

 The example below performs estimation using the default regression models for $E[Y_|A^s_i,W^s_i]$, $P_{\mathbf{g}_0}(A^s|W^s)$ and  $P_{\mathbf{g}^*}(A^s|W^s)$.

```{r}
f.gstar <- create_f.gstar(shift = shift.const, trunc = trunc.const)

print_tmlenet_opts()
tmlenet_options(maxNperBin = 1000, bin.method="equal.mass")

res1 <- tmlenet(data = datO, Anode = "sA", Ynode = "Y",
                Kmax = Kmax,
                NETIDmat = NetInd_mat,
                f_gstar1 = f.gstar,
                sW = def_sW, sA = def_sA,
                optPars = list(n_MCsims = 1))

```

The output of the `tmlenet` function call is named list with 3 items:

1. `EY_gstar1` - the estimates of the mean counterfactual outcome under (stochastic) intervention function `f_gstar1` ($E_{g^*_1}[Y]$); 
2. `EY_gstar2` - the same estimates under for intervention `f_gstar2` ($E_{g^*_2}[Y]$), `NULL` if `f_gstar2` not specified;
3. `ATE` - the additive treatment effect ($E_{g^*_1}[Y] - E_{g^*_2}[Y]$) under interventions `f_gstar1` and `f_gstar2`, `NULL` if `f_gstar2` not specified.


Each of this list will contain items `estimates`, `vars`, `CIs`, `h_g0_SummariesModel` and `h_gstar_SummariesModel`.


`estimates` either provides the estimated mean outcome for the corresponding stochastic interventions `f_gstar1` or `f_gstar2` or the ATE, for the TMLE, IPTW and G-COMP estimators, as shown below:

```{r}
res1$EY_gstar1$estimates
```
The asymptotic variance estimates are provided in `vars`:

```{r}
res1$EY_gstar1$vars
```

The `alpha`-level asymptotic confidence intervals (based on the asymptotic normality of the TMLE and IPTW) are provided in `CI` (the default `alpha` is set to 0.95):

```{r}
res1$EY_gstar1$CIs
```

Finally, `h_g0_SummariesModel` and `h_gstar_SummariesModel` provide the model fits for the exposure model $P(A^s|W^s)$, for the observed exposure mechanism $\mathbf{g}_0$ and for the stochastic intervention (either `f_gstar1` or `f_gstar2`), respectively, as shown below:

```{r}
res1$EY_gstar1$h_g0_SummariesModel
res1$EY_gstar1$h_gstar_SummariesModel
```

## Estimation example 2.

The example below shows how to specify the regression models for the conditional mean outcome `Y` as a function of the above defined summary measures. The first model is a correctly specified model (`Qform.corr`), while the second one a misspecified model (`Qform.mis`):

```{r}
Qform.corr <- "Y ~ W1 + W2 + W3 + sA + net.mean.sA + net.mean.W1"
Qform.mis <- "Y ~ W2 + W3 + net.mean.sA"
```

Specifying the exposure regression model under observed exposure mechanism $\mathbf{g}_0$:

```{r}
hform.g0 <- "sA + net.mean.sA ~ W1 + W2 + W3"
```

Specifying the exposure regression model under user-specified stochastic intervention $\mathbf{g}^*$ :

```{r}
hform.gstar = "sA + net.mean.sA ~ W1 + W2 + W3"
```

```{r}
res2 <- tmlenet(data = datO, Kmax = Kmax, NETIDmat = NetInd_mat,
                sW = def_sW, sA = def_sA,
                Anode = "sA", Ynode = "Y",
                f_gstar1 = f.gstar,
                Qform = Qform.corr, hform.g0 = hform.g0, hform.gstar = hform.gstar,
                optPars = list(n_MCsims = 1))
res2$EY_gstar1$estimates
```

## Estimation example 3.

We now run the TMLE estimation for networks by calling the `tmlenet` function and providing the above defined inputs, but using the misspecified conditional outcome model defined in `Qform.mis`:

```{r, message=FALSE}
res3 <- tmlenet(data = datO, Kmax = Kmax, NETIDmat = NetInd_mat, 
                sW = def_sW, sA = def_sA, 
                Anode = "sA", Ynode = "Y",
                f_gstar1 = f.gstar,
                Qform = Qform.mis, hform.g0 = hform.g0, hform.gstar = hform.gstar,
                optPars = list(n_MCsims = 1))
res3$EY_gstar1$estimates
```


<!-- \section{Discussion}\label{secdiscus} -->
<!-- % \addcontentsline{toc}{section}{Discussion} -->

<!-- \section*{Acknowledgments} -->
<!-- \textbf{FUNDING ACKNOWLEDGEMENT}:  -->

<!-- % \bibliographystyle{unsrt} -->
<!-- \bibliography{SimCausal_2014,R-Pckgs} -->

# References

