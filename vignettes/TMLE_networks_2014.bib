Automatically generated by Mendeley Desktop 1.14
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{yu2003measuring,
author = {Yu, Zhuo and van der Laan, Mark J},
journal = {U.C. Berkeley Division of Biostatistics Working Paper Series},
number = {Working Paper 136},
publisher = {bepress},
title = {{Measuring treatment effects using semiparametric models}},
url = {http://biostats.bepress.com/ucbbiostat/paper136},
year = {2003}
}
@inproceedings{ugander2013graph,
author = {Ugander, Johan and Karrer, Brian and Backstrom, Lars and Kleinberg, Jon},
booktitle = {Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
organization = {ACM},
pages = {329--337},
title = {{Graph cluster randomization: Network exposure to multiple universes}},
year = {2013}
}
@incollection{vanderweele2013social,
author = {VanderWeele, Tyler J and An, Weihua},
booktitle = {Handbook of Causal Analysis for Social Research},
pages = {353--374},
publisher = {Springer},
title = {{Social networks and causal inference}},
year = {2013}
}
@article{christakis2007spread,
author = {Christakis, Nicholas A and Fowler, James H},
journal = {New England journal of medicine},
number = {4},
pages = {370--379},
publisher = {Mass Medical Soc},
title = {{The spread of obesity in a large social network over 32 years}},
volume = {357},
year = {2007}
}
@article{gill2001causal,
author = {Gill, Richard D and Robins, James M},
journal = {Annals of Statistics},
pages = {1785--1811},
publisher = {JSTOR},
title = {{Causal inference for complex longitudinal data: the continuous case}},
year = {2001}
}
@article{Aral2011,
author = {Aral, Sinan and Walker, Dylan},
doi = {10.1109/MIS.2011.89},
journal = {IEEE Intelligent Systems},
number = {5},
pages = {91--96},
title = {{Identifying Social Influence in Networks Using Randomized Experiments}},
url = {http://dx.doi.org/10.1109/MIS.2011.89},
volume = {26},
year = {2011}
}
@article{robins1999choice,
author = {Robins, James M},
journal = {Statistical Science},
pages = {281--293},
publisher = {JSTOR},
title = {[choice as an alternative to control in observational studies]: comment},
year = {1999}
}
@article{robins2010stochasticg,
author = {Robins, James M and Richardson, Thomas},
journal = {Causality and psychopathology: Finding the determinants of disorders and their cures},
pages = {103--158},
publisher = {Oxford Univ. Press, Oxford},
title = {{Alternative graphical causal models and the identification of direct effects}},
year = {2010}
}
@article{rubin1986statistics,
author = {Rubin, Donald B},
journal = {Journal of the American Statistical Association},
number = {396},
pages = {961--962},
title = {{Statistics and causal inference: Comment: Which ifs have causal answers}},
volume = {81},
year = {1986}
}
@article{vanderweele2014interference,
author = {VanderWeele, Tyler J and Tchetgen, Eric J Tchetgen and Halloran, M Elizabeth and Others},
journal = {Statistical Science},
number = {4},
pages = {687--706},
publisher = {Institute of Mathematical Statistics},
title = {{Interference and sensitivity analysis}},
volume = {29},
year = {2014}
}
@article{vdL2013datatarget,
author = {van der Laan, Mark J and Hubbard, Alan E and Pajouh, Sara Kherad},
journal = {U.C. Berkeley Division of Biostatistics Working Paper Series},
number = {Working Paper 314},
publisher = {bepress},
title = {{Statistical inference for data adaptive target parameters}},
url = {http://biostats.bepress.com/ucbbiostat/paper314},
year = {2013}
}
@article{lyons2011spread,
abstract = {The chronic widespread misuse of statistics is usually inadvertent, not intentional. We find cautionary examples in a series of recent papers by Christakis and Fowler that advance statistical arguments for the transmission via social networks of various personal characteristics, including obesity, smoking cessation, happiness, and loneliness. Those papers also assert that such influence extends to three degrees of separation in social networks. We shall show that these conclusions do not follow from Christakis and Fowler's statistical analyses. In fact, their studies even provide some evidence against the existence of such transmission. The errors that we expose arose, in part, because the assumptions behind the statistical procedures used were insufficiently examined, not only by the authors, but also by the reviewers. Our examples are instructive because the practitioners are highly reputed, their results have received enormous popular attention, and the journals that published their studies are among the most respected in the world. An educational bonus emerges from the difficulty we report in getting our critique published. We discuss the relevance of this episode to understanding statistical literacy and the role of scientific review, as well as to reforming statistics education.},
archivePrefix = {arXiv},
arxivId = {1007.2876},
author = {Lyons, Russell},
doi = {10.2202/2151-7509.1024},
eprint = {1007.2876},
isbn = {2151-7509},
issn = {2151-7509},
journal = {Statistics, Politics, and Policy},
number = {1},
pages = {1--26},
title = {{The Spread of Evidence-Poor Medicine via Flawed Social-Network Analysis}},
url = {http://arxiv.org/abs/1007.2876},
volume = {2},
year = {2010}
}
@article{shalizi2011homophily,
author = {Shalizi, Cosma Rohilla and Thomas, Andrew C},
journal = {Sociological methods \& research},
number = {2},
pages = {211--239},
publisher = {Sage Publications},
title = {{Homophily and contagion are generically confounded in observational social network studies}},
volume = {40},
year = {2011}
}
@article{zheng2012causal,
author = {Zheng, Wenjing and van der Laan, Mark J},
journal = {U.C. Berkeley Division of Biostatistics Working Paper Series},
number = {Working Paper 295},
title = {{Causal mediation in a survival setting with time-dependent mediators}},
url = {http://biostats.bepress.com/ucbbiostat/paper295},
year = {2012}
}
@article{Aral2014,
author = {Aral, Sinan and Walker, Dylan},
doi = {10.1287/mnsc.2014.1936},
journal = {Management Science},
number = {6},
pages = {1352--1370},
title = {{Tie Strength, Embeddedness, and Social Influence: A Large-Scale Networked Experiment}},
url = {http://dx.doi.org/10.1287/mnsc.2014.1936},
volume = {60},
year = {2014}
}
@article{bowers2013reasoning,
abstract = {If an experimental treatment is experienced by both treated and control group units, tests of hypotheses about causal effects may be difficult to conceptualize, let alone execute. In this article, we show how counterfactual causal models may be written and tested when theories suggest spillover or other network-based interference among experimental units. We show that the “no interference” assumption need not constrain scholars who have interesting questions about interference. We offer researchers the ability to model theories about how treatment given to some units may come to influence outcomes for other units. We further show how to test hypotheses about these causal effects, and we provide tools to enable researchers to assess the operating characteristics of their tests given their own models, designs, test statistics, and data. The conceptual and methodological framework we develop here is particularly applicable to social networks, but may be usefully deployed whenever a researcher wonders about interference between units. Interference between units need not be an untestable assumption; instead, interference is an opportunity to ask meaningful questions about theoretically interesting phenomena.},
author = {Bowers, Jake and Fredrickson, Mark M. and Panagopoulos, Costas},
doi = {10.1093/pan/mps038},
isbn = {1047-1987; 1476-4989},
issn = {10471987},
journal = {Political Analysis},
number = {1},
pages = {97--124},
publisher = {SPM-PMSAPSA},
title = {{Reasoning about interference between units: A general framework}},
volume = {21},
year = {2013}
}
@book{van1996weak,
author = {{Van Der Vaart}, Aad W and Wellner, Jon A},
publisher = {Springer},
title = {{Weak Convergence}},
year = {1996}
}
@article{robins1986new,
abstract = {In observational cohort mortality studies with prolonged periods of exposure to the agent under study, it is not uncommon for risk factors for death to be determinants of subsequent exposure. For instance, in occupational mortality studies date of termination of employment is both a determinant of future exposure (since terminated individuals receive no further exposure) and an independent risk factor for death (since disabled individuals tend to leave employment). When current risk factor status determines subsequent exposure and is determined by previous exposure, standard analyses that estimate age-specific mortality rates as a function of cumulative exposure may underestimate the true effect of exposure on mortality whether or not one adjusts for the risk factor in the analysis. This observation raises the question, which if any population parameters can be given a causal interpretation in observational mortality studies?},
author = {Robins, James M},
doi = {10.1016/0898-1221(87)90238-0},
isbn = {0270-0255},
issn = {08981221},
journal = {Computers \& Mathematics with Applications},
number = {9-12},
pages = {923--945},
publisher = {Elsevier},
title = {{Addendum to "a new approach to causal inference in mortality studies with a sustained exposure period-application to control of the healthy worker survivor effect"}},
volume = {14},
year = {1987}
}
@article{vdL2006targeted,
abstract = {Suppose one observes a sample of independent and identically distributed observations from a particular data generating distribution. Suppose that one is concerned with estimation of a particular pathwise differentiable Euclidean parameter. A substitution estimator evaluating the parameter of a given likelihood based density estimator is typically too biased and might not even converge at the parametric rate: that is, the density estimator was targeted to be a good estimator of the density and might therefore result in a poor estimator of a particular smooth functional of the density. In this article we propose a one step (and, by iteration, k-th step) targeted maximum likelihood density estimator which involves 1) creating a hardest parametric submodel with parameter epsilon through the given density estimator with score equal to the efficient influence curve of the pathwise differentiable parameter at the density estimator, 2) estimating epsilon with the maximum likelihood estimator, and 3) defining a new density estimator as the corresponding update of the original density estimator. We show that iteration of this algorithm results in a targeted maximum likelihood density estimator which solves the efficient influence curve estimating equation and thereby yields a locally efficient estimator of the parameter of interest, under regularity conditions. In particular, we show that, if the parameter is linear and the model is convex, then the targeted maximum likelihood estimator is often achieved in the first step, and it results in a locally efficient estimator at an arbitrary (e.g., heavily misspecified) starting density. We also show that the targeted maximum likelihood estimators are now in full agreement with the locally efficient estimating function methodology as presented in Robins and Rotnitzky (1992) and van der Laan and Robins (2003), creating, in particular, algebraic equivalence between the double robust locally efficient estimators using the targeted maximum likelihood estimators as an estimate of its nuisance parameters, and targeted maximum likelihood estimators. In addition, it is argued that the targeted MLE has various advantages relative to the current estimating function based approach. We proceed by providing data driven methodologies to select the initial density estimator for the targeted MLE, thereby providing data adaptive targeted maximum likelihood estimation methodology. We illustrate the method with various worked out examples.},
author = {van der Laan, Mark J. and Rubin, Daniel},
doi = {10.2202/1557-4679.1043},
isbn = {15574679},
issn = {1557-4679},
journal = {The International Journal of Biostatistics},
keywords = {causal effect, cross-validation, efficient influen},
number = {1},
title = {{Targeted Maximum Likelihood Learning}},
volume = {2},
year = {2006}
}
@article{vanderweele2012components,
abstract = {Vaccination of one person may prevent the infection of another either because the vaccine prevents the first from being infected and from infecting the second, or because, even if the first person is infected, the vaccine may render the infection less infectious. We might refer to the first of these mechanisms as a contagion effect and the second as an infectiousness effect. In the simple setting of a randomized vaccine trial with households of size two, we use counterfactual theory under interference to provide formal definitions of a contagion effect and an unconditional infectiousness effect. Using ideas analogous to mediation analysis, we show that the indirect effect (the effect of one person's vaccine on another's outcome) can be decomposed into a contagion effect and an unconditional infectiousness effect on the risk difference, risk ratio, odds ratio, and vaccine efficacy scales. We provide identification assumptions for such contagion and unconditional infectiousness effects and describe a simple statistical technique to estimate these effects when they are identified. We also give a sensitivity analysis technique to assess how inferences would change under violations of the identification assumptions. The concepts and results of this paper are illustrated with hypothetical vaccine trial data.},
author = {VanderWeele, Tyler J and {Tchetgen Tchetgen}, Eric J. and Halloran, M Elizabeth},
doi = {10.1097/EDE.0b013e31825fb7a0},
issn = {1044-3983},
journal = {Epidemiology},
number = {5},
pages = {751--761},
publisher = {NIH Public Access},
title = {{Components of the Indirect Effect in Vaccine Trials}},
volume = {23},
year = {2012}
}
@article{dawid2010identifying,
author = {Dawid, A Philip and Didelez, Vanessa and Others},
journal = {Statistics Surveys},
pages = {184--231},
publisher = {The author, under a Creative Commons Attribution License},
title = {{Identifying the consequences of dynamic treatment strategies: A decision-theoretic overview}},
volume = {4},
year = {2010}
}
@article{Ogburn2014,
abstract = {Consider the causal effect that one individual's treatment may have on another individual's outcome when the outcome is contagious, with specific application to the effect of vaccination on an infectious disease outcome. The effect of one individual's vaccination on another's outcome can be decomposed into two different causal effects, called the "infectiousness" and "contagion" effects. We present identifying assumptions and estimation or testing procedures for infectiousness and contagion effects in two different settings: (1) using data sampled from independent groups of observations, and (2) using data collected from a single interdependent social network. The methods that we propose for social network data require fitting generalized linear models (GLMs). GLMs and other statistical models that require independence across subjects have been used widely to estimate causal effects in social network data, but, because the subjects in networks are presumably not independent, the use of such models is generally invalid, resulting in inference that is expected to be anticonservative. We introduce a way to ensure that GLM residuals are uncorrelated across subjects despite the fact that outcomes are non-independent. This simultaneously demonstrates the possibility of using GLMs and related statistical models for network data and highlights their limitations.},
archivePrefix = {arXiv},
arxivId = {1403.1241},
author = {Ogburn, Elizabeth L. and VanderWeele, Tyler J.},
eprint = {1403.1241},
month = mar,
pages = {28},
title = {{Vaccines, Contagion, and Social Networks}},
url = {http://arxiv.org/abs/1403.1241},
year = {2014}
}
@article{eckles2014design,
author = {Eckles, Dean and Karrer, Brian and Ugander, Johan},
journal = {arXiv preprint},
title = {{Design and analysis of experiments in networks: Reducing bias from interference}},
year = {2014}
}
@article{vanderweele2013inference,
author = {VanderWeele, Tyler J},
journal = {Statistics in medicine},
number = {4},
pages = {591--596},
publisher = {Wiley Online Library},
title = {{Inference for influence over multiple degrees of separation on a social network}},
volume = {32},
year = {2013}
}
@article{o2013analysis,
author = {O'Malley, A James},
journal = {Statistics in medicine},
number = {4},
pages = {539--555},
publisher = {Wiley Online Library},
title = {{The analysis of social network data: an exciting frontier for statisticians}},
volume = {32},
year = {2013}
}
@article{balzer2015targeted,
author = {Balzer, Laura and Petersen, Maya and Laan, Mark Van Der},
journal = {U.C. Berkeley Division of Biostatistics Working Paper Series},
number = {Working Paper 334},
title = {{Targeted Estimation and Inference for the Sample Average Treatment Effect}},
url = {http://biostats.bepress.com/ucbbiostat/paper334},
year = {2015}
}
@article{vdL2014nets,
abstract = {Suppose that we observe a population of causally connected units. On each unit at each time-point on a grid we observe a set of other units the unit is potentially connected with, and a unit-specific longitudinal data structure consisting of baseline and time-dependent covariates, a time-dependent treatment, and a final outcome of interest. The target quantity of interest is defined as the mean outcome for this group of units if the exposures of the units would be probabilistically assigned according to a known specified mechanism, where the latter is called a stochastic intervention. Causal effects of interest are defined as contrasts of the mean of the unit-specific outcomes under different stochastic interventions one wishes to evaluate. This covers a large range of estimation problems from independent units, independent clusters of units, and a single cluster of units in which each unit has a limited number of connections to other units. The allowed dependence includes treatment allocation in response to data on multiple units and so called causal interference as special cases. We present a few motivating classes of examples, propose a structural causal model, define the desired causal quantities, address the identification of these quantities from the observed data, and define maximum likelihood based estimators based on cross-validation. In particular, we present maximum likelihood based super-learning for this network data. Nonetheless, such smoothed/regularized maximum likelihood estimators are not targeted and will thereby be overly bias w.r.t. the target parameter, and, as a consequence, generally not result in asymptotically normally distributed estimators of the statistical target parameter. To formally develop estimation theory, we focus on the simpler case in which the longitudinal data structure is a point-treatment data structure. We formulate a novel targeted maximum likelihood estimator of this estimand and show that the double robustness of the efficient influence curve implies that the bias of the targeted minimum loss-based estimation (TMLE) will be a second-order term involving squared differences of two nuisance parameters. In particular, the TMLE will be consistent if either one of these nuisance parameters is consistently estimated. Due to the causal dependencies between units, the data set may correspond with the realization of a single experiment, so that establishing a (e.g. normal) limit distribution for the targeted maximum likelihood estimators, and corresponding statistical inference, is a challenging topic. We prove two formal theorems establishing the asymptotic normality using advances in weak-convergence theory. We conclude with a discussion and refer to an accompanying technical report for extensions to general longitudinal data structures.},
author = {van der Laan, Mark J.},
doi = {10.1515/jci-2013-0002},
issn = {2193-3677},
journal = {Journal of Causal Inference},
keywords = {1 introduction and motivation,berkeley,ca,causal inference,corresponding author,e-mail,edu,efficient influence curve,laan,mark j,networks,stochastic intervention,targeted maximum likelihood estimation,university of california,usa,van der laan},
month = mar,
number = {1},
pages = {1--62},
title = {{Causal Inference for a Population of Causally Connected Units}},
url = {http://www.degruyter.com/view/j/jci.ahead-of-print/jci-2013-0002/jci-2013-0002.xml},
volume = {2},
year = {2014}
}
@article{vaart2006oracle,
author = {Vaart, Aad W and Dudoit, Sandrine and Laan, Mark J},
journal = {Statistics \& Decisions},
number = {3},
pages = {351--371},
title = {{Oracle inequalities for multi-fold cross validation}},
volume = {24},
year = {2006}
}
@article{neyman1923applications,
author = {Neyman, Jerzy},
journal = {Statistical Science},
pages = {465--480},
title = {{Sur les applications de la theorie des probabilites aux experiences agricoles: Essai des principes (In Polish). English translation by DM Dabrowska and TP Speed (1990)}},
volume = {5},
year = {1923}
}
@article{gruber2009targeted,
author = {Gruber, Susan and van der Laan, Mark J},
journal = {U.C. Berkeley Division of Biostatistics Working Paper Series},
number = {Working Paper 252},
publisher = {bepress},
title = {{Targeted maximum likelihood estimation: A gentle introduction}},
url = {http://biostats.bepress.com/ucbbiostat/paper252},
year = {2009}
}
@article{hudgens2008toward,
author = {Hudgens, Michael G and Halloran, M Elizabeth},
journal = {Journal of the American Statistical Association},
number = {482},
title = {{Toward causal inference with interference}},
volume = {103},
year = {2008}
}
@incollection{robins1997causal,
archivePrefix = {arXiv},
arxivId = {New York, NY: Springer},
author = {Robins, James M},
booktitle = {Latent variable modeling and applications to causality},
doi = {10.1007/978-1-4612-1842-5\_4},
eprint = {New York, NY: Springer},
isbn = {978-1-4612-1842-5},
pages = {69--117},
publisher = {Springer},
title = {{Causal inference from complex longitudinal data}},
url = {http://link.springer.com/chapter/10.1007/978-1-4612-1842-5\_4},
year = {1997}
}
@book{vdL2011targetedbook,
author = {van der Laan, Mark and Rose, Sherri},
publisher = {Springer Series in Statistics},
title = {{Targeted learning: causal inference for observational and experimental data}},
year = {2011}
}
@article{2006Sobel,
author = {Sobel, Michael E},
doi = {10.1198/016214506000000636},
journal = {Journal of the American Statistical Association},
number = {476},
pages = {1398--1407},
title = {{What Do Randomized Studies of Housing Mobility Demonstrate?}},
url = {http://dx.doi.org/10.1198/016214506000000636},
volume = {101},
year = {2006}
}
@article{liu2014large,
abstract = {Recently, increasing attention has focused on making causal inference when interference is possible. In the presence of interference, treatment may have several types of effects. In this paper, we consider inference about such effects when the population consists of groups of individuals where interference is possible within groups but not between groups. A two stage randomization design is assumed where in the first stage groups are randomized to different treatment allocation strategies and in the second stage individuals are randomized to treatment or control conditional on the strategy assigned to their group in the first stage. For this design, the asymptotic distributions of estimators of the causal effects are derived when either the number of individuals per group or the number of groups grows large. Under certain homogeneity assumptions, the asymptotic distributions provide justification for Wald-type confidence intervals (CIs) and tests. Empirical results demonstrate the Wald CIs have good coverage in finite samples and are narrower than CIs based on either the Chebyshev or Hoeffding inequalities provided the number of groups is not too small. The methods are illustrated by two examples which consider the effects of cholera vaccination and an intervention to encourage voting.},
author = {Liu, Lan and Hudgens, Michael G},
doi = {10.1080/01621459.2013.844698},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {causal inference,confidence interval,normal mixture,spillover},
number = {505},
pages = {288--301},
pmid = {24659836},
publisher = {Taylor \& Francis},
title = {{Large sample randomization inference of causal effects in the presence of interference.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3960089\&tool=pmcentrez\&rendertype=abstract},
volume = {109},
year = {2014}
}
@article{rosenbaum2007interference,
abstract = {In a randomized experiment comparing two treatments, there is interference between units if applying the treatment to one unit may affect other units. Interference implies that treatment effects are not comparisons of two potential responses that a unit may exhibit, one under treatment and the other under control, but instead are inherently more complex. Interference is common in social settings where people communicate, compete, or spread disease; in studies that treat one part of an organism using a symmetrical part as control; in studies that apply different treatments to the same organism at different times; and in many other situations. Available statistical tools are limited. For instance, Fisher's sharp null hypothesis of no treatment effect implicitly entails no interference, and so his randomization test may be used to test no effect, but conventional ways of inverting the test to obtain confidence intervals, say for an additive effect, are not applicable with interference. Another commonly used approach assumes that interference is of a simple parametric form confined to units that are near one another in time or space; this is useful when applicable but is of little use when interference may be widespread and of uncertain form. Exact, nonparametric methods are developed for inverting randomization tests to obtain confidence intervals for magnitudes of effect assuming nothing at all about the structure of the interference between units. The limitations of these methods are discussed. To illustrate the general approach, two simple methods and two simple empirical examples are discussed. Extension to randomization based covariance adjustment is briefly described.},
author = {Rosenbaum, Paul R},
doi = {10.1198/016214506000001112},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {1,1 what is interference,attributable effect,between different units,between units,causal effect,examples and review,interference,introduction,randomized experiment,sutva,there is no,wrote},
number = {477},
pages = {191--200},
title = {{Interference Between Units in Randomized Experiments}},
volume = {102},
year = {2007}
}
@article{munoz2012population,
author = {Mu\~{n}oz, Iv\'{a}n D\'{\i}az and van der Laan, Mark},
journal = {Biometrics},
number = {2},
pages = {541--549},
publisher = {Blackwell Publishing Inc},
title = {{Population intervention causal effects based on stochastic interventions}},
volume = {68},
year = {2012}
}
@inproceedings{toulis2013estimation,
author = {Toulis, Panos and Kao, Edward},
booktitle = {Proceedings of The 30th International Conference on Machine Learning},
pages = {1489--1497},
title = {{Estimation of causal peer influence effects}},
year = {2013}
}
@article{Aronow2013,
abstract = {This paper presents a randomization-based framework for estimating causal effects under interference between units. The framework integrates three components: (i) an experimental design that defines the probability distribution of treatment assignments, (ii) a mapping that relates experimental treatment assignments to exposures received by units in the experiment, and (iii) estimands that make use of the experiment to answer questions of substantive interest. Using this framework, we develop the case of estimating average unit-level causal effects from a randomized experiment with interference of arbitrary but known form. The resulting estimators are based on inverse probability weighting. We provide randomization-based variance estimators that account for the complex clustering that can occur when interference is present. We also establish consistency and asymptotic normality under local dependence assumptions. We discuss refinements including covariate-adjusted effect estimators and ratio estimation. We illustrate and assess empirical performance with a naturalistic simulation using network data from American high schools.},
archivePrefix = {arXiv},
arxivId = {1305.6156},
author = {Aronow, Peter M. and Samii, Cyrus},
eprint = {1305.6156},
journal = {ArXiv e-prints},
month = may,
title = {{Estimating Average Causal Effects Under Interference Between Units}},
url = {http://arxiv.org/abs/1305.6156},
year = {2013}
}
@book{bickel1997,
abstract = {This book is about estimation in situations where we believe we have$\backslash$nenough knowledge to model some features of the data parametrically,$\backslash$nbut are unwilling to assume anything for other features. Such models$\backslash$nhave arisen in a wide variety of contexts in recent years, particularly$\backslash$nin economics, epidemiology, and astronomy. The complicated structure$\backslash$nof these models typically requires us to consider nonlinear estimation$\backslash$nprocedures which often can only be implemented algorithmically. The$\backslash$ntheory of these procedures is necessarily based on asymptotic approximations.},
author = {Bickel, Peter J},
booktitle = {Johns Hopkins series in the mathematical sciences},
isbn = {0801845416 (acid-free paper)},
issn = {0026-1335},
keywords = {Asymptotic expansions.,Estimation theory.,Mathematical,Models,Statistical inference,model},
pages = {xix, 560},
pmid = {1689},
publisher = {New York, New York: Springer-Verlag.},
title = {{Efficient and adaptive estimation for semiparametric models}},
year = {1993}
}
@article{steeg2012statistical,
author = {Steeg, Greg Ver and Galstyan, Aram},
journal = {arXiv preprint arXiv:1211.4889},
title = {{Statistical tests for contagion in observational social network studies}},
year = {2012}
}
@article{vanderweele2012and,
author = {VanderWeele, Tyler J and Ogburn, Elizabeth L and {Tchetgen Tchetgen}, Eric J},
journal = {Statistics, politics, and policy},
number = {1},
title = {{Why and when" flawed" social network analyses still yield valid tests of no contagion}},
volume = {3},
year = {2012}
}
@book{Pearl2009,
address = {New York, NY, USA},
author = {Pearl, Judea},
edition = {2nd},
isbn = {052189560X, 9780521895606},
publisher = {Cambridge University Press},
title = {{Causality: Models, Reasoning and Inference}},
year = {2009}
}
@article{robins1987graphical,
abstract = {In observational cohort mortality studies with prolonged periods of exposure to the agent under study, independent risk factors for death commonly determine subsequent exposure to the study agent. For example, in occupational mortality studies, date of termination of employment is both a determinant of subsequent exposure to the chemical agent under study (since terminated individuals receive no further exposure) and an independent risk factor for death (since disabled individuals tend to leave employment). When a risk factor determines subsequent exposure and is determined by previous exposure, standard analyses that estimate age-specific mortality rates as a function of cumulative exposure can underestimate the true effect of exposure on mortality, whether or not one adjusts for the risk factor in the analysis. This observation raises the question, "Which, if any, empirical population parameter can be causally interpreted as the true effect of exposure in observational mortality studies?" In answer, we offer a graphical approach to the identification and estimation of causal parameters in mortality studies with sustained exposure periods. We reanalyze the mortality experience of a cohort of arsenic-exposed copper smelter workers using our approach and compare our results with those obtained using standard methods. We find an adverse effect of arsenic exposure on all cause and lung cancer mortality, which standard methods failed to detect. The analytic approach introduced in this paper may be necessary to control bias in any epidemiologic study in which there exists a risk factor which both determines subsequent exposure and is determined by previous exposure to the agent under study.},
author = {Robins, James M},
doi = {10.1016/S0021-9681(87)80018-8},
isbn = {0021-9681 (Print)$\backslash$r0021-9681 (Linking)},
issn = {00219681},
journal = {Journal of chronic diseases},
pages = {139S--161S},
pmid = {3667861},
publisher = {Elsevier},
title = {{A graphical approach to the identification and estimation of causal parameters in mortality studies with sustained exposure periods.}},
url = {http://dx.doi.org/10.1016/S0021-9681(87)80018-8},
volume = {40 Suppl 2},
year = {1987}
}
@article{vanderweele2011sensitivity,
author = {VanderWeele, Tyler J},
journal = {Sociological Methods \& Research},
number = {2},
pages = {240--255},
publisher = {Sage Publications},
title = {{Sensitivity analysis for contagion effects in social networks}},
volume = {40},
year = {2011}
}
@article{Choi2014,
abstract = {Randomized experiments on social networks are a trending research topic. Such experiments pose statistical challenges due to the possibility of interference between units. We propose a new method for estimating attributable treatment effects under interference. The method does not require partial interference, but instead uses an identifying assumption that is similar to requiring nonnegative treatment effects. Observed pre-treatment social network information can be used to customize the test statistic, so as to increase power without making assumptions on the data generating process. The inversion of the test statistic is a combinatorial optimization problem which has a tractable relaxation, yielding conservative estimates of the attributable effect.},
archivePrefix = {arXiv},
arxivId = {1408.4102},
author = {Choi, David S.},
eprint = {1408.4102},
journal = {ArXiv e-prints},
keywords = {attributable effect,causal inference,facebook,graph cut,interference,network data,randomized experiments},
month = aug,
title = {{Estimation of Monotone Treatment Effects in Network Experiments}},
url = {http://arxiv.org/abs/1408.4102},
year = {2014}
}
@article{tchetgen2012causal,
author = {Tchetgen, Eric J Tchetgen and VanderWeele, Tyler J},
journal = {Statistical Methods in Medical Research},
number = {1},
pages = {55--75},
publisher = {SAGE Publications},
title = {{On causal inference in the presence of interference}},
volume = {21},
year = {2012}
}
@article{steglich2010dynamic,
author = {Steglich, Christian and Snijders, Tom A B and Pearson, Michael},
journal = {Sociological methodology},
number = {1},
pages = {329--393},
publisher = {Wiley Online Library},
title = {{Dynamic networks and behavior: Separating selection from influence}},
volume = {40},
year = {2010}
}
@article{christakis2013social,
author = {Christakis, Nicholas A and Fowler, James H},
journal = {Statistics in medicine},
number = {4},
pages = {556--577},
publisher = {Wiley Online Library},
title = {{Social contagion theory: examining dynamic social networks and human behavior}},
volume = {32},
year = {2013}
}
@article{basse2015,
abstract = {We consider the problem of how to assign treatment in a randomized experiment, when the correlation among the outcomes is informed by a network available pre-intervention. Working within the potential outcome causal framework, we develop a class of models that posit such a correlation structure among the outcomes, and a strategy for allocating treatment optimally, for the goal of minimizing the integrated mean squared error of the estimated average treatment effect. We provide insights into features of the optimal designs via an analytical decomposition of the mean squared error used for optimization. We illustrate how the proposed treatment allocation strategy improves on allocations that ignore the network structure, with extensive simulations.},
archivePrefix = {arXiv},
arxivId = {1507.00803},
author = {Basse, Guillaume W. and Airoldi, Edoardo M.},
eprint = {1507.00803},
journal = {ArXiv e-prints},
keywords = {Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Machine Learning,Statistics - Methodology},
month = jul,
pages = {29},
title = {{Optimal design of experiments in the presence of network-correlated outcomes}},
url = {http://arxiv.org/abs/1507.00803},
year = {2015}
}
@article{walker2014design,
abstract = {Over the last decade, the emergence of pervasive online and digitally enabled environments has created a rich source of detailed data on human behavior. Yet, the promise of big data has recently come under fire for its inability to separate correlation from causation - to derive actionable insights and yield effective policies. Fortunately, the same online platforms on which we interact on a day-to-day basis permit experimentation at large scales, ushering in a new movement toward big experiments. Randomized controlled trials are the heart of the scientific method and when designed correctly provide clean causal inferences that are robust and reproducible. However, the realization that our world is highly connected and that behavioral and economic outcomes at the individual and population level depend upon this connectivity challenges the very principles of experimental design. The proper design and analysis of experiments in networks is, therefore, critically important. In this work, we categorize and review the emerging strategies to design and analyze experiments in networks and discuss their strengths and weaknesses.},
author = {Walker, Dylan and Muchnik, Lev},
doi = {10.1109/JPROC.2014.2363674},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
number = {12},
pages = {1940--1951},
publisher = {IEEE},
title = {{Design of Randomized Experiments in Networks}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6945782},
volume = {102},
year = {2014}
}
